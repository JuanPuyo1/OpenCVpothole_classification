{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "PROYECTOFINAL.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACZaJNodMqaI"
      },
      "source": [
        "# **Automatic system for the detection of potholes in the BogotÃ¡ road network assisted by digital images.**\n",
        "\n",
        "#### Juan Esteban Puyo\n",
        "#### Johan Santiago Gomez\n",
        "#### Laura Alejandra Rocha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9WUbnLBNBV9"
      },
      "source": [
        "## **Implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-PZ7KLZNEgn"
      },
      "source": [
        "Based on the proposed project requirements, the final delivery will consist of developing a pothole identifier using OpenCV, a free computer vision library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uzAN8SRxth-",
        "outputId": "4d0704f9-352f-4a6b-e234-e516bf83247c"
      },
      "source": [
        "#First part, import of the TensorFlow library, for compatibility issues it was decided to import a version 1.x\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyRxd7O9nY6w",
        "outputId": "8d654aff-da11-4609-eede-b2ea1a543cd6"
      },
      "source": [
        "#Librery Importation\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "import cv2\n",
        "import copy\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "from keras.utils import Sequence\n",
        "import xml.etree.ElementTree as ET"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGaR6kMrz_AA",
        "outputId": "01ab777a-f5ed-4ee0-fa4e-c5149b48ac6e"
      },
      "source": [
        "#labelImg, necesary for the dataset strcuture.\n",
        "!pip install labelImg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: labelImg in /usr/local/lib/python3.7/dist-packages (1.8.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from labelImg) (4.2.6)\n",
            "Requirement already satisfied: pyqt5 in /usr/local/lib/python3.7/dist-packages (from labelImg) (5.15.4)\n",
            "Requirement already satisfied: PyQt5-Qt5>=5.15 in /usr/local/lib/python3.7/dist-packages (from pyqt5->labelImg) (5.15.2)\n",
            "Requirement already satisfied: PyQt5-sip<13,>=12.8 in /usr/local/lib/python3.7/dist-packages (from pyqt5->labelImg) (12.9.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ly0Af1mF0VIx"
      },
      "source": [
        "import labelImg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CH1oqU5RtOL2",
        "outputId": "16b7a129-f0f7-4cb0-896f-4ae34e119bac"
      },
      "source": [
        "#Drive necesary to dataset access\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEXfLBHQo5gr"
      },
      "source": [
        "xml_dir =  \"/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/bachexml/\" #directorio que contiene los xml\n",
        "img_dir = \"/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/\"  # directorios con las imagenes\n",
        "labels = [\"bache\"]\n",
        "tamanio = 416  # tamanio en pixeles para entrenar la red \n",
        "mejores_pesos = \"red_bache.h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s4E58oFtmeT"
      },
      "source": [
        "#The same storage classification method was used for the images, for each image its XML file is associated.\n",
        "def leer_annotations(ann_dir, img_dir, labels=[]):\n",
        "    all_imgs = []\n",
        "    seen_labels = {}\n",
        "    \n",
        "    for ann in [x for x in sorted(os.listdir(ann_dir)) if x.endswith('.xml')] :\n",
        "        img = {'object':[]}\n",
        "        \n",
        "        tree = ET.parse(ann_dir + ann)\n",
        "        \n",
        "        for elem in tree.iter():\n",
        "            if 'filename' in elem.tag:\n",
        "                img['filename'] = img_dir + elem.text\n",
        "                print(img)\n",
        "            if 'width' in elem.tag:\n",
        "                img['width'] = int(elem.text)\n",
        "            if 'height' in elem.tag:\n",
        "                img['height'] = int(elem.text)\n",
        "            if 'object' in elem.tag or 'part' in elem.tag:\n",
        "                obj = {}\n",
        "                \n",
        "                for attr in list(elem):\n",
        "                    if 'name' in attr.tag:\n",
        "                        obj['name'] = attr.text\n",
        "\n",
        "                        if obj['name'] in seen_labels:\n",
        "                            seen_labels[obj['name']] += 1\n",
        "                        else:\n",
        "                            seen_labels[obj['name']] = 1\n",
        "                        \n",
        "                        if len(labels) > 0 and obj['name'] not in labels:\n",
        "                            break\n",
        "                        else:\n",
        "                            img['object'] += [obj]\n",
        "                            \n",
        "                    if 'bndbox' in attr.tag:\n",
        "                        for dim in list(attr):\n",
        "                            if 'xmin' in dim.tag:\n",
        "                                obj['xmin'] = int(round(float(dim.text)))\n",
        "                            if 'ymin' in dim.tag:\n",
        "                                obj['ymin'] = int(round(float(dim.text)))\n",
        "                            if 'xmax' in dim.tag:\n",
        "                                obj['xmax'] = int(round(float(dim.text)))\n",
        "                            if 'ymax' in dim.tag:\n",
        "                                obj['ymax'] = int(round(float(dim.text)))\n",
        "\n",
        "        if len(img['object']) > 0:\n",
        "            all_imgs += [img]\n",
        "                        \n",
        "    return all_imgs, seen_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1hszGTMtsAX",
        "outputId": "69b3a310-c2ba-4de2-e53b-912ac38a6f51"
      },
      "source": [
        "train_imgs, train_labels = leer_annotations(xml_dir, img_dir, labels)\n",
        "print('imagenes',len(train_imgs), 'labels',len(train_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/1.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/10.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/100.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/101.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/102.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/103.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/104.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/105.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/106.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/107.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/108.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/109.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/11.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/110.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/111.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/112.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/113.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/114.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/115.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/116.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/117.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/118.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/119.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/12.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/120.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/121.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/122.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/123.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/124.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/125.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/126.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/127.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/128.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/129.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/13.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/130.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/131.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/132.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/133.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/134.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/135.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/136.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/137.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/138.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/139.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/14.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/140.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/141.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/142.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/143.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/144.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/145.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/146.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/147.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/148.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/149.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/15.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/150.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/151.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/152.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/153.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/154.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/155.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/156.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/157.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/158.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/159.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/16.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/160.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/161.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/162.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/163.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/164.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/165.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/166.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/167.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/168.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/169.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/17.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/170.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/171.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/172.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/173.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/175.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/176.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/177.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/178.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/179.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/18.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/180.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/181.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/182.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/183.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/184.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/185.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/186.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/187.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/188.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/189.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/19.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/190.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/191.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/192.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/193.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/194.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/195.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/196.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/197.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/198.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/199.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/2.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/20.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/200.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/201.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/202.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/203.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/204.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/205.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/206.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/207.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/208.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/209.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/21.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/210.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/211.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/212.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/213.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/214.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/215.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/216.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/217.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/218.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/219.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/22.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/220.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/221.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/222.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/223.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/224.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/225.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/226.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/227.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/228.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/229.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/23.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/230.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/231.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/232.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/233.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/234.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/235.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/236.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/237.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/238.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/239.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/24.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/240.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/241.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/242.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/243.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/244.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/245.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/246.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/247.jpeg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/248.jpeg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/249.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/25.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/259.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/26.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/260.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/262.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/263.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/264.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/265.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/266.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/267.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/268.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/269.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/27.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/270.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/271.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/272.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/273.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/274.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/275.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/276.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/277.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/278.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/279.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/28.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/280.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/281.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/282.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/283.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/284.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/285.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/286.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/287.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/288.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/289.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/290.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/291.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/292.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/293.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/294.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/295.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/296.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/297.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/298.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/299.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/3.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/30.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/300.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/301.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/302.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/303.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/304.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/305.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/306.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/307.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/308.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/309.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/31.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/310.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/311.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/312.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/313.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/314.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/315.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/316.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/317.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/318.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/319.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/32.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/320.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/321.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/322.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/323.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/324.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/325.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/326.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/327.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/328.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/329.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/33.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/330.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/331.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/332.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/333.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/334.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/335.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/336.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/337.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/338.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/339.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/34.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/340.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/341.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/342.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/343.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/344.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/345.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/346.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/347.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/348.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/349.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/35.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/350.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/351.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/352.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/353.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/354.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/355.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/356.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/357.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/358.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/359.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/36.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/360.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/361.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/362.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/363.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/364.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/365.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/366.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/367.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/368.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/369.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/37.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/370.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/371.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/372.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/373.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/374.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/375.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/376.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/377.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/378.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/379.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/38.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/380.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/381.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/382.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/383.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/384.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/385.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/386.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/387.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/388.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/389.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/39.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/390.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/391.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/392.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/393.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/394.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/395.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/396.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/397.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/398.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/399.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/4.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/40.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/400.JPG'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/401.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/402.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/403.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/404.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/405.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/406.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/407.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/408.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/409.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/41.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/410.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/411.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/412.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/413.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/414.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/415.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/416.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/417.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/419.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/42.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/421.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/422.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/423.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/424.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/425.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/426.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/427.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/428.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/429.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/43.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/430.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/432.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/433.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/434.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/435.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/436.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/437.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/438.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/439.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/440.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/441.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/442.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/443.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/444.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/445.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/446.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/447.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/448.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/449.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/450.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/451.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/452.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/453.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/454.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/455.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/456.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/457.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/458.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/459.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/46.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/460.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/461.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/462.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/463.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/464.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/465.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/466.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/467.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/468.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/47.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/470.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/471.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/472.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/473.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/474.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/475.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/476.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/477.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/478.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/479.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/48.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/480.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/481.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/482.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/483.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/484.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/485.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/486.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/487.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/488.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/489.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/49.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/490.png'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/5.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/50.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/500.jpeg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/501.jpeg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/502.jpeg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/503.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/504.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/505.jpeg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/506.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/507.jpeg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/508.jpeg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/509.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/51.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/510.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/511.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/512.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/513.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/514.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/515.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/516.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/517.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/518.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/519.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/52.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/520.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/53.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/54.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/55.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/56.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/57.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/58.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/59.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/6.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/60.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/61.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/62.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/63.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/64.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/65.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/66.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/67.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/68.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/69.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/7.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/70.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/71.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/72.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/73.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/74.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/75.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/76.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/77.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/78.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/79.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/8.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/80.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/81.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/82.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/83.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/84.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/85.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/86.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/87.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/88.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/89.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/9.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/90.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/91.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/92.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/93.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/94.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/95.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/96.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/97.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/98.jpg'}\n",
            "{'object': [], 'filename': '/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/PROYECTO/bachesImagenes/baches/99.jpg'}\n",
            "imagenes 493 labels 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFF9gTS1voSo",
        "outputId": "7e439bbb-6221-43df-84f8-83c79aee80e7"
      },
      "source": [
        "train_valid_split = int(0.8*len(train_imgs))\n",
        "np.random.shuffle(train_imgs)\n",
        "valid_imgs = train_imgs[train_valid_split:]\n",
        "train_imgs = train_imgs[:train_valid_split]\n",
        "print('train:',len(train_imgs), 'validate:',len(valid_imgs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: 394 validate: 99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu_3QCzIv6VG"
      },
      "source": [
        "#augmentors by https://github.com/aleju/imgaug\n",
        "def bbox_iou(box1, box2):\n",
        "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])  \n",
        "    \n",
        "    intersect = intersect_w * intersect_h\n",
        "\n",
        "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "    \n",
        "    union = w1*h1 + w2*h2 - intersect\n",
        "    \n",
        "    return float(intersect) / union\n",
        "\n",
        "class BoundBox:\n",
        "    def __init__(self, xmin, ymin, xmax, ymax, c = None, classes = None):\n",
        "        self.xmin = xmin\n",
        "        self.ymin = ymin\n",
        "        self.xmax = xmax\n",
        "        self.ymax = ymax\n",
        "        \n",
        "        self.c     = c\n",
        "        self.classes = classes\n",
        "\n",
        "        self.label = -1\n",
        "        self.score = -1\n",
        "\n",
        "    def get_label(self):\n",
        "        if self.label == -1:\n",
        "            self.label = np.argmax(self.classes)\n",
        "        \n",
        "        return self.label\n",
        "    \n",
        "    def get_score(self):\n",
        "        if self.score == -1:\n",
        "            self.score = self.classes[self.get_label()]\n",
        "            \n",
        "        return self.score\n",
        "\n",
        "\n",
        "class BatchGenerator(Sequence):\n",
        "    def __init__(self, images, \n",
        "                       config, \n",
        "                       shuffle=True, \n",
        "                       jitter=True, \n",
        "                       norm=None):\n",
        "        self.generator = None\n",
        "\n",
        "        self.images = images\n",
        "        self.config = config\n",
        "\n",
        "        self.shuffle = shuffle\n",
        "        self.jitter  = jitter\n",
        "        self.norm    = norm\n",
        "\n",
        "        self.anchors = [BoundBox(0, 0, config['ANCHORS'][2*i], config['ANCHORS'][2*i+1]) for i in range(int(len(config['ANCHORS'])//2))]\n",
        "\n",
        "        ### augmentors by https://github.com/aleju/imgaug\n",
        "        sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "\n",
        "        self.aug_pipe = iaa.Sequential(\n",
        "            [\n",
        "                sometimes(iaa.Affine()),\n",
        "                iaa.SomeOf((0, 5),\n",
        "                    [\n",
        "                        iaa.OneOf([\n",
        "                            iaa.GaussianBlur((0, 3.0)), # blur images with a sigma between 0 and 3.0\n",
        "                            iaa.AverageBlur(k=(2, 7)), # blur image using local means with kernel sizes between 2 and 7\n",
        "                            iaa.MedianBlur(k=(3, 11)), # blur image using local medians with kernel sizes between 2 and 7\n",
        "                        ]),\n",
        "                        iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images\n",
        "                        iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), # add gaussian noise to images\n",
        "                        iaa.OneOf([\n",
        "                            iaa.Dropout((0.01, 0.1), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
        "                        ]),\n",
        "                        iaa.Add((-10, 10), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
        "                        iaa.Multiply((0.5, 1.5), per_channel=0.5), # change brightness of images (50-150% of original value)\n",
        "                        iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5), # improve or worsen the contrast\n",
        "                    ],\n",
        "                    random_order=True\n",
        "                )\n",
        "            ],\n",
        "            random_order=True\n",
        "        )\n",
        "\n",
        "        if shuffle: np.random.shuffle(self.images)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(float(len(self.images))/self.config['BATCH_SIZE']))   \n",
        "\n",
        "    def num_classes(self):\n",
        "        return len(self.config['LABELS'])\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.images)    \n",
        "\n",
        "    def load_annotation(self, i):\n",
        "        annots = []\n",
        "\n",
        "        for obj in self.images[i]['object']:\n",
        "            annot = [obj['xmin'], obj['ymin'], obj['xmax'], obj['ymax'], self.config['LABELS'].index(obj['name'])]\n",
        "            annots += [annot]\n",
        "\n",
        "        if len(annots) == 0: annots = [[]]\n",
        "\n",
        "        return np.array(annots)\n",
        "\n",
        "    def load_image(self, i):\n",
        "        return cv2.imread(self.images[i]['filename'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        l_bound = idx*self.config['BATCH_SIZE']\n",
        "        r_bound = (idx+1)*self.config['BATCH_SIZE']\n",
        "\n",
        "        if r_bound > len(self.images):\n",
        "            r_bound = len(self.images)\n",
        "            l_bound = r_bound - self.config['BATCH_SIZE']\n",
        "\n",
        "        instance_count = 0\n",
        "\n",
        "        x_batch = np.zeros((r_bound - l_bound, self.config['IMAGE_H'], self.config['IMAGE_W'], 3))                         # input images\n",
        "        b_batch = np.zeros((r_bound - l_bound, 1     , 1     , 1    ,  self.config['TRUE_BOX_BUFFER'], 4))   # list of self.config['TRUE_self.config['BOX']_BUFFER'] GT boxes\n",
        "        y_batch = np.zeros((r_bound - l_bound, self.config['GRID_H'],  self.config['GRID_W'], self.config['BOX'], 4+1+len(self.config['LABELS'])))                # desired network output\n",
        "\n",
        "        for train_instance in self.images[l_bound:r_bound]:\n",
        "            # augment input image and fix object's position and size\n",
        "            img, all_objs = self.aug_image(train_instance, jitter=self.jitter)\n",
        "            \n",
        "            # construct output from object's x, y, w, h\n",
        "            true_box_index = 0\n",
        "            \n",
        "            for obj in all_objs:\n",
        "                if obj['xmax'] > obj['xmin'] and obj['ymax'] > obj['ymin'] and obj['name'] in self.config['LABELS']:\n",
        "                    center_x = .5*(obj['xmin'] + obj['xmax'])\n",
        "                    center_x = center_x / (float(self.config['IMAGE_W']) / self.config['GRID_W'])\n",
        "                    center_y = .5*(obj['ymin'] + obj['ymax'])\n",
        "                    center_y = center_y / (float(self.config['IMAGE_H']) / self.config['GRID_H'])\n",
        "\n",
        "                    grid_x = int(np.floor(center_x))\n",
        "                    grid_y = int(np.floor(center_y))\n",
        "\n",
        "                    if grid_x < self.config['GRID_W'] and grid_y < self.config['GRID_H']:\n",
        "                        obj_indx  = self.config['LABELS'].index(obj['name'])\n",
        "                        \n",
        "                        center_w = (obj['xmax'] - obj['xmin']) / (float(self.config['IMAGE_W']) / self.config['GRID_W']) # unit: grid cell\n",
        "                        center_h = (obj['ymax'] - obj['ymin']) / (float(self.config['IMAGE_H']) / self.config['GRID_H']) # unit: grid cell\n",
        "                        \n",
        "                        box = [center_x, center_y, center_w, center_h]\n",
        "\n",
        "                        # find the anchor that best predicts this box\n",
        "                        best_anchor = -1\n",
        "                        max_iou     = -1\n",
        "                        \n",
        "                        shifted_box = BoundBox(0, \n",
        "                                               0,\n",
        "                                               center_w,                                                \n",
        "                                               center_h)\n",
        "                        \n",
        "                        for i in range(len(self.anchors)):\n",
        "                            anchor = self.anchors[i]\n",
        "                            iou    = bbox_iou(shifted_box, anchor)\n",
        "                            \n",
        "                            if max_iou < iou:\n",
        "                                best_anchor = i\n",
        "                                max_iou     = iou\n",
        "                                \n",
        "                        # assign ground truth x, y, w, h, confidence and class probs to y_batch\n",
        "                        y_batch[instance_count, grid_y, grid_x, best_anchor, 0:4] = box\n",
        "                        y_batch[instance_count, grid_y, grid_x, best_anchor, 4  ] = 1.\n",
        "                        y_batch[instance_count, grid_y, grid_x, best_anchor, 5+obj_indx] = 1\n",
        "                        \n",
        "                        # assign the true box to b_batch\n",
        "                        b_batch[instance_count, 0, 0, 0, true_box_index] = box\n",
        "                        \n",
        "                        true_box_index += 1\n",
        "                        true_box_index = true_box_index % self.config['TRUE_BOX_BUFFER']\n",
        "                            \n",
        "            # assign input image to x_batch\n",
        "            if self.norm != None: \n",
        "                x_batch[instance_count] = self.norm(img)\n",
        "            else:\n",
        "                # plot image and bounding boxes for sanity check\n",
        "                for obj in all_objs:\n",
        "                    if obj['xmax'] > obj['xmin'] and obj['ymax'] > obj['ymin']:\n",
        "                        cv2.rectangle(img[:,:,::-1], (obj['xmin'],obj['ymin']), (obj['xmax'],obj['ymax']), (255,0,0), 3)\n",
        "                        cv2.putText(img[:,:,::-1], obj['name'], \n",
        "                                    (obj['xmin']+2, obj['ymin']+12), \n",
        "                                    0, 1.2e-3 * img.shape[0], \n",
        "                                    (0,255,0), 2)\n",
        "                        \n",
        "                x_batch[instance_count] = img\n",
        "\n",
        "            # increase instance counter in current batch\n",
        "            instance_count += 1  \n",
        "\n",
        "        #print(' new batch created', idx)\n",
        "\n",
        "        return [x_batch, b_batch], y_batch\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle: np.random.shuffle(self.images)\n",
        "\n",
        "    def aug_image(self, train_instance, jitter):\n",
        "        image_name = train_instance['filename']\n",
        "        image = cv2.imread(image_name)\n",
        "\n",
        "        if image is None: print('Cannot find ', image_name)\n",
        "          #stream = open(image_name, \"rb\")\n",
        "          #bytes = bytearray(stream.read())\n",
        "          #numpyarray = numpy.asarray(bytes, dtype=numpy.uint8)\n",
        "          #bgrImage = cv2.imdecode(numpyarray, cv2.IMREAD_UNCHANGED)\n",
        "        h, w, c = image.shape\n",
        "        all_objs = copy.deepcopy(train_instance['object'])\n",
        "\n",
        "        if jitter:\n",
        "            ### scale the image\n",
        "            scale = np.random.uniform() / 10. + 1.\n",
        "            image = cv2.resize(image, (0,0), fx = scale, fy = scale)\n",
        "\n",
        "            ### translate the image\n",
        "            max_offx = (scale-1.) * w\n",
        "            max_offy = (scale-1.) * h\n",
        "            offx = int(np.random.uniform() * max_offx)\n",
        "            offy = int(np.random.uniform() * max_offy)\n",
        "            \n",
        "            image = image[offy : (offy + h), offx : (offx + w)]\n",
        "\n",
        "            ### flip the image\n",
        "            flip = np.random.binomial(1, .5)\n",
        "            if flip > 0.5: image = cv2.flip(image, 1)\n",
        "                \n",
        "            image = self.aug_pipe.augment_image(image)            \n",
        "            \n",
        "        # resize the image to standard size\n",
        "        image = cv2.resize(image, (self.config['IMAGE_H'], self.config['IMAGE_W']))\n",
        "        image = image[:,:,::-1]\n",
        "\n",
        "        # fix object's position and size\n",
        "        for obj in all_objs:\n",
        "            for attr in ['xmin', 'xmax']:\n",
        "                if jitter: obj[attr] = int(obj[attr] * scale - offx)\n",
        "                    \n",
        "                obj[attr] = int(obj[attr] * float(self.config['IMAGE_W']) / w)\n",
        "                obj[attr] = max(min(obj[attr], self.config['IMAGE_W']), 0)\n",
        "                \n",
        "            for attr in ['ymin', 'ymax']:\n",
        "                if jitter: obj[attr] = int(obj[attr] * scale - offy)\n",
        "                    \n",
        "                obj[attr] = int(obj[attr] * float(self.config['IMAGE_H']) / h)\n",
        "                obj[attr] = max(min(obj[attr], self.config['IMAGE_H']), 0)\n",
        "\n",
        "            if jitter and flip > 0.5:\n",
        "                xmin = obj['xmin']\n",
        "                obj['xmin'] = self.config['IMAGE_W'] - obj['xmax']\n",
        "                obj['xmax'] = self.config['IMAGE_W'] - xmin\n",
        "                \n",
        "        return image, all_objs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hluoXX9iv7xl"
      },
      "source": [
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "\n",
        "\n",
        "FULL_YOLO_BACKEND_PATH  = \"/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/full_yolo_backend.h5\"   # should be hosted on a server\n",
        "\n",
        "class BaseFeatureExtractor(object):\n",
        "    \"\"\"docstring for ClassName\"\"\"\n",
        "\n",
        "    # to be defined in each subclass\n",
        "    def __init__(self, input_size):\n",
        "        raise NotImplementedError(\"error message\")\n",
        "\n",
        "    # to be defined in each subclass\n",
        "    def normalize(self, image):\n",
        "        raise NotImplementedError(\"error message\")       \n",
        "\n",
        "    def get_output_shape(self):\n",
        "        return self.feature_extractor.get_output_shape_at(-1)[1:3]\n",
        "\n",
        "    def extract(self, input_image):\n",
        "        return self.feature_extractor(input_image)\n",
        "\n",
        "class FullYoloFeature(BaseFeatureExtractor):\n",
        "    \"\"\"docstring for ClassName\"\"\"\n",
        "    def __init__(self, input_size):\n",
        "        input_image = Input(shape=(input_size, input_size, 3))\n",
        "\n",
        "        # the function to implement the orgnization layer (thanks to github.com/allanzelener/YAD2K)\n",
        "        def space_to_depth_x2(x):\n",
        "            return tf.space_to_depth(x, block_size=2)\n",
        "\n",
        "        # Layer 1\n",
        "        x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
        "        x = BatchNormalization(name='norm_1')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "        # Layer 2\n",
        "        x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_2')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "        # Layer 3\n",
        "        x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_3')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 4\n",
        "        x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_4')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 5\n",
        "        x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_5')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "        # Layer 6\n",
        "        x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_6')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 7\n",
        "        x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_7')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 8\n",
        "        x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_8')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "        # Layer 9\n",
        "        x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_9')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 10\n",
        "        x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_10')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 11\n",
        "        x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_11')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 12\n",
        "        x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_12')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 13\n",
        "        x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_13')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        skip_connection = x\n",
        "\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "        # Layer 14\n",
        "        x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_14')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 15\n",
        "        x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_15')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 16\n",
        "        x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_16')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 17\n",
        "        x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_17')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 18\n",
        "        x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_18')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 19\n",
        "        x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_19')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 20\n",
        "        x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_20')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 21\n",
        "        skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
        "        skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
        "        skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
        "        skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
        "\n",
        "        x = concatenate([skip_connection, x])\n",
        "\n",
        "        # Layer 22\n",
        "        x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_22')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        self.feature_extractor = Model(input_image, x)\n",
        "        self.feature_extractor.load_weights(FULL_YOLO_BACKEND_PATH)\n",
        "\n",
        "    def normalize(self, image):\n",
        "        return image / 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbcM6u5gxD7W"
      },
      "source": [
        "# funciones que necesitaremos\n",
        "\n",
        "def _sigmoid(x):\n",
        "    return 1. / (1. + np.exp(-x))\n",
        "\n",
        "def _softmax(x, axis=-1, t=-100.):\n",
        "    x = x - np.max(x)\n",
        "    \n",
        "    if np.min(x) < t:\n",
        "        x = x/np.min(x)*t\n",
        "        \n",
        "    e_x = np.exp(x)\n",
        "    \n",
        "    return e_x / e_x.sum(axis, keepdims=True)\n",
        "\n",
        "def _interval_overlap(interval_a, interval_b):\n",
        "    x1, x2 = interval_a\n",
        "    x3, x4 = interval_b\n",
        "\n",
        "    if x3 < x1:\n",
        "        if x4 < x1:\n",
        "            return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x1\n",
        "    else:\n",
        "        if x2 < x3:\n",
        "             return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x3          \n",
        "\n",
        "def compute_overlap(a, b):\n",
        "    \"\"\"\n",
        "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
        "    Parameters\n",
        "    ----------\n",
        "    a: (N, 4) ndarray of float\n",
        "    b: (K, 4) ndarray of float\n",
        "    Returns\n",
        "    -------\n",
        "    overlaps: (N, K) ndarray of overlap between boxes and query_boxes\n",
        "    \"\"\"\n",
        "    area = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1])\n",
        "\n",
        "    iw = np.minimum(np.expand_dims(a[:, 2], axis=1), b[:, 2]) - np.maximum(np.expand_dims(a[:, 0], 1), b[:, 0])\n",
        "    ih = np.minimum(np.expand_dims(a[:, 3], axis=1), b[:, 3]) - np.maximum(np.expand_dims(a[:, 1], 1), b[:, 1])\n",
        "\n",
        "    iw = np.maximum(iw, 0)\n",
        "    ih = np.maximum(ih, 0)\n",
        "\n",
        "    ua = np.expand_dims((a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1]), axis=1) + area - iw * ih\n",
        "\n",
        "    ua = np.maximum(ua, np.finfo(float).eps)\n",
        "\n",
        "    intersection = iw * ih\n",
        "\n",
        "    return intersection / ua  \n",
        "    \n",
        "def compute_ap(recall, precision):\n",
        "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
        "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
        "\n",
        "    # Arguments\n",
        "        recall:    The recall curve (list).\n",
        "        precision: The precision curve (list).\n",
        "    # Returns\n",
        "        The average precision as computed in py-faster-rcnn.\n",
        "    \"\"\"\n",
        "    # correct AP calculation\n",
        "    # first append sentinel values at the end\n",
        "    mrec = np.concatenate(([0.], recall, [1.]))\n",
        "    mpre = np.concatenate(([0.], precision, [0.]))\n",
        "\n",
        "    # compute the precision envelope\n",
        "    for i in range(mpre.size - 1, 0, -1):\n",
        "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
        "\n",
        "    # to calculate area under PR curve, look for points\n",
        "    # where X axis (recall) changes value\n",
        "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
        "\n",
        "    # and sum (\\Delta recall) * prec\n",
        "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
        "    return ap      \n",
        "\n",
        "def decode_netout(netout, anchors, nb_class, obj_threshold=0.3, nms_threshold=0.3):\n",
        "    grid_h, grid_w, nb_box = netout.shape[:3]\n",
        "\n",
        "    boxes = []\n",
        "    \n",
        "    # decode the output by the network\n",
        "    netout[..., 4]  = _sigmoid(netout[..., 4])\n",
        "    netout[..., 5:] = netout[..., 4][..., np.newaxis] * _softmax(netout[..., 5:])\n",
        "    netout[..., 5:] *= netout[..., 5:] > obj_threshold\n",
        "    \n",
        "    for row in range(grid_h):\n",
        "        for col in range(grid_w):\n",
        "            for b in range(nb_box):\n",
        "                # from 4th element onwards are confidence and class classes\n",
        "                classes = netout[row,col,b,5:]\n",
        "                \n",
        "                if np.sum(classes) > 0:\n",
        "                    # first 4 elements are x, y, w, and h\n",
        "                    x, y, w, h = netout[row,col,b,:4]\n",
        "\n",
        "                    x = (col + _sigmoid(x)) / grid_w # center position, unit: image width\n",
        "                    y = (row + _sigmoid(y)) / grid_h # center position, unit: image height\n",
        "                    w = anchors[2 * b + 0] * np.exp(w) / grid_w # unit: image width\n",
        "                    h = anchors[2 * b + 1] * np.exp(h) / grid_h # unit: image height\n",
        "                    confidence = netout[row,col,b,4]\n",
        "                    \n",
        "                    box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, confidence, classes)\n",
        "                    \n",
        "                    boxes.append(box)\n",
        "\n",
        "    # suppress non-maximal boxes\n",
        "    for c in range(nb_class):\n",
        "        sorted_indices = list(reversed(np.argsort([box.classes[c] for box in boxes])))\n",
        "\n",
        "        for i in range(len(sorted_indices)):\n",
        "            index_i = sorted_indices[i]\n",
        "            \n",
        "            if boxes[index_i].classes[c] == 0: \n",
        "                continue\n",
        "            else:\n",
        "                for j in range(i+1, len(sorted_indices)):\n",
        "                    index_j = sorted_indices[j]\n",
        "                    \n",
        "                    if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_threshold:\n",
        "                        boxes[index_j].classes[c] = 0\n",
        "                        \n",
        "    # remove the boxes which are less likely than a obj_threshold\n",
        "    boxes = [box for box in boxes if box.get_score() > obj_threshold]\n",
        "    \n",
        "    return boxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG_VWCa0xI52"
      },
      "source": [
        "class YOLO(object):\n",
        "    def __init__(self, \n",
        "                       input_size, \n",
        "                       labels, \n",
        "                       max_box_per_image,\n",
        "                       anchors):\n",
        "\n",
        "        self.input_size = input_size\n",
        "        \n",
        "        self.labels   = list(labels)\n",
        "        self.nb_class = len(self.labels)\n",
        "        self.nb_box   = len(anchors)//2\n",
        "        self.class_wt = np.ones(self.nb_class, dtype='float32')\n",
        "        self.anchors  = anchors\n",
        "\n",
        "        self.max_box_per_image = max_box_per_image\n",
        "\n",
        "        ##########################\n",
        "        # Make the model\n",
        "        ##########################\n",
        "\n",
        "        # make the feature extractor layers\n",
        "        input_image     = Input(shape=(self.input_size, self.input_size, 3))\n",
        "        self.true_boxes = Input(shape=(1, 1, 1, max_box_per_image , 4))  \n",
        "\n",
        "        self.feature_extractor = FullYoloFeature(self.input_size)\n",
        "\n",
        "        print(self.feature_extractor.get_output_shape())    \n",
        "        self.grid_h, self.grid_w = self.feature_extractor.get_output_shape()        \n",
        "        features = self.feature_extractor.extract(input_image)            \n",
        "\n",
        "        # make the object detection layer\n",
        "        output = Conv2D(self.nb_box * (4 + 1 + self.nb_class), \n",
        "                        (1,1), strides=(1,1), \n",
        "                        padding='same', \n",
        "                        name='DetectionLayer', \n",
        "                        kernel_initializer='lecun_normal')(features)\n",
        "        output = Reshape((self.grid_h, self.grid_w, self.nb_box, 4 + 1 + self.nb_class))(output)\n",
        "        output = Lambda(lambda args: args[0])([output, self.true_boxes])\n",
        "\n",
        "        self.model = Model([input_image, self.true_boxes], output)\n",
        "\n",
        "        \n",
        "        # initialize the weights of the detection layer\n",
        "        layer = self.model.layers[-4]\n",
        "        weights = layer.get_weights()\n",
        "\n",
        "        new_kernel = np.random.normal(size=weights[0].shape)/(self.grid_h*self.grid_w)\n",
        "        new_bias   = np.random.normal(size=weights[1].shape)/(self.grid_h*self.grid_w)\n",
        "\n",
        "        layer.set_weights([new_kernel, new_bias])\n",
        "\n",
        "        # print a summary of the whole model\n",
        "        self.model.summary()\n",
        "\n",
        "    def custom_loss(self, y_true, y_pred):\n",
        "        mask_shape = tf.shape(y_true)[:4]\n",
        "        \n",
        "        cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(self.grid_w), [self.grid_h]), (1, self.grid_h, self.grid_w, 1, 1)))\n",
        "        cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
        "\n",
        "        cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [self.batch_size, 1, 1, self.nb_box, 1])\n",
        "        \n",
        "        coord_mask = tf.zeros(mask_shape)\n",
        "        conf_mask  = tf.zeros(mask_shape)\n",
        "        class_mask = tf.zeros(mask_shape)\n",
        "        \n",
        "        seen = tf.Variable(0.)\n",
        "        total_recall = tf.Variable(0.)\n",
        "        \n",
        "        \"\"\"\n",
        "        Adjust prediction\n",
        "        \"\"\"\n",
        "        ### adjust x and y      \n",
        "        pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
        "        \n",
        "        ### adjust w and h\n",
        "        pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(self.anchors, [1,1,1,self.nb_box,2])\n",
        "        \n",
        "        ### adjust confidence\n",
        "        pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
        "        \n",
        "        ### adjust class probabilities\n",
        "        pred_box_class = y_pred[..., 5:]\n",
        "        \n",
        "        \"\"\"\n",
        "        Adjust ground truth\n",
        "        \"\"\"\n",
        "        ### adjust x and y\n",
        "        true_box_xy = y_true[..., 0:2] # relative position to the containing cell\n",
        "        \n",
        "        ### adjust w and h\n",
        "        true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically\n",
        "        \n",
        "        ### adjust confidence\n",
        "        true_wh_half = true_box_wh / 2.\n",
        "        true_mins    = true_box_xy - true_wh_half\n",
        "        true_maxes   = true_box_xy + true_wh_half\n",
        "        \n",
        "        pred_wh_half = pred_box_wh / 2.\n",
        "        pred_mins    = pred_box_xy - pred_wh_half\n",
        "        pred_maxes   = pred_box_xy + pred_wh_half       \n",
        "        \n",
        "        intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
        "        intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "        intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "        intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "        \n",
        "        true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
        "        pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
        "\n",
        "        union_areas = pred_areas + true_areas - intersect_areas\n",
        "        iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
        "        \n",
        "        true_box_conf = iou_scores * y_true[..., 4]\n",
        "        \n",
        "        ### adjust class probabilities\n",
        "        true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
        "        \n",
        "        \"\"\"\n",
        "        Determine the masks\n",
        "        \"\"\"\n",
        "        ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
        "        coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * self.coord_scale\n",
        "        \n",
        "        ### confidence mask: penelize predictors + penalize boxes with low IOU\n",
        "        # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
        "        true_xy = self.true_boxes[..., 0:2]\n",
        "        true_wh = self.true_boxes[..., 2:4]\n",
        "        \n",
        "        true_wh_half = true_wh / 2.\n",
        "        true_mins    = true_xy - true_wh_half\n",
        "        true_maxes   = true_xy + true_wh_half\n",
        "        \n",
        "        pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
        "        pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
        "        \n",
        "        pred_wh_half = pred_wh / 2.\n",
        "        pred_mins    = pred_xy - pred_wh_half\n",
        "        pred_maxes   = pred_xy + pred_wh_half    \n",
        "        \n",
        "        intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
        "        intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "        intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "        intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "        \n",
        "        true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
        "        pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
        "\n",
        "        union_areas = pred_areas + true_areas - intersect_areas\n",
        "        iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
        "\n",
        "        best_ious = tf.reduce_max(iou_scores, axis=4)\n",
        "        conf_mask = conf_mask + tf.to_float(best_ious < 0.6) * (1 - y_true[..., 4]) * self.no_object_scale\n",
        "        \n",
        "        # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
        "        conf_mask = conf_mask + y_true[..., 4] * self.object_scale\n",
        "        \n",
        "        ### class mask: simply the position of the ground truth boxes (the predictors)\n",
        "        class_mask = y_true[..., 4] * tf.gather(self.class_wt, true_box_class) * self.class_scale       \n",
        "        \n",
        "        \"\"\"\n",
        "        Warm-up training\n",
        "        \"\"\"\n",
        "        no_boxes_mask = tf.to_float(coord_mask < self.coord_scale/2.)\n",
        "        seen = tf.assign_add(seen, 1.)\n",
        "        \n",
        "        true_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen, self.warmup_batches+1), \n",
        "                              lambda: [true_box_xy + (0.5 + cell_grid) * no_boxes_mask, \n",
        "                                       true_box_wh + tf.ones_like(true_box_wh) * \\\n",
        "                                       np.reshape(self.anchors, [1,1,1,self.nb_box,2]) * \\\n",
        "                                       no_boxes_mask, \n",
        "                                       tf.ones_like(coord_mask)],\n",
        "                              lambda: [true_box_xy, \n",
        "                                       true_box_wh,\n",
        "                                       coord_mask])\n",
        "        \n",
        "        \"\"\"\n",
        "        Finalize the loss\n",
        "        \"\"\"\n",
        "        nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
        "        nb_conf_box  = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\n",
        "        nb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\n",
        "        \n",
        "        loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
        "        loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
        "        loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box  + 1e-6) / 2.\n",
        "        loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
        "        loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6)\n",
        "        \n",
        "        loss = tf.cond(tf.less(seen, self.warmup_batches+1), \n",
        "                      lambda: loss_xy + loss_wh + loss_conf + loss_class + 10,\n",
        "                      lambda: loss_xy + loss_wh + loss_conf + loss_class)\n",
        "        \n",
        "        if self.debug:\n",
        "            nb_true_box = tf.reduce_sum(y_true[..., 4])\n",
        "            nb_pred_box = tf.reduce_sum(tf.to_float(true_box_conf > 0.5) * tf.to_float(pred_box_conf > 0.3))\n",
        "            \n",
        "            current_recall = nb_pred_box/(nb_true_box + 1e-6)\n",
        "            total_recall = tf.assign_add(total_recall, current_recall) \n",
        "\n",
        "            loss = tf.Print(loss, [loss_xy], message='Loss XY \\t', summarize=1000)\n",
        "            loss = tf.Print(loss, [loss_wh], message='Loss WH \\t', summarize=1000)\n",
        "            loss = tf.Print(loss, [loss_conf], message='Loss Conf \\t', summarize=1000)\n",
        "            loss = tf.Print(loss, [loss_class], message='Loss Class \\t', summarize=1000)\n",
        "            loss = tf.Print(loss, [loss], message='Total Loss \\t', summarize=1000)\n",
        "            loss = tf.Print(loss, [current_recall], message='Current Recall \\t', summarize=1000)\n",
        "            loss = tf.Print(loss, [total_recall/seen], message='Average Recall \\t', summarize=1000)\n",
        "        \n",
        "        return loss\n",
        "\n",
        "    def load_weights(self, weight_path):\n",
        "        self.model.load_weights(weight_path)\n",
        "\n",
        "    def train(self, train_imgs,     # the list of images to train the model\n",
        "                    valid_imgs,     # the list of images used to validate the model\n",
        "                    train_times,    # the number of time to repeat the training set, often used for small datasets\n",
        "                    valid_times,    # the number of times to repeat the validation set, often used for small datasets\n",
        "                    nb_epochs,      # number of epoches\n",
        "                    learning_rate,  # the learning rate\n",
        "                    batch_size,     # the size of the batch\n",
        "                    warmup_epochs,  # number of initial batches to let the model familiarize with the new dataset\n",
        "                    object_scale,\n",
        "                    no_object_scale,\n",
        "                    coord_scale,\n",
        "                    class_scale,\n",
        "                    saved_weights_name='best_weights.h5',\n",
        "                    debug=False):     \n",
        "\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.object_scale    = object_scale\n",
        "        self.no_object_scale = no_object_scale\n",
        "        self.coord_scale     = coord_scale\n",
        "        self.class_scale     = class_scale\n",
        "\n",
        "        self.debug = debug\n",
        "\n",
        "        ############################################\n",
        "        # Make train and validation generators\n",
        "        ############################################\n",
        "\n",
        "        generator_config = {\n",
        "            'IMAGE_H'         : self.input_size, \n",
        "            'IMAGE_W'         : self.input_size,\n",
        "            'GRID_H'          : self.grid_h,  \n",
        "            'GRID_W'          : self.grid_w,\n",
        "            'BOX'             : self.nb_box,\n",
        "            'LABELS'          : self.labels,\n",
        "            'CLASS'           : len(self.labels),\n",
        "            'ANCHORS'         : self.anchors,\n",
        "            'BATCH_SIZE'      : self.batch_size,\n",
        "            'TRUE_BOX_BUFFER' : self.max_box_per_image,\n",
        "        }    \n",
        "\n",
        "        train_generator = BatchGenerator(train_imgs, \n",
        "                                     generator_config, \n",
        "                                     norm=self.feature_extractor.normalize)\n",
        "        valid_generator = BatchGenerator(valid_imgs, \n",
        "                                     generator_config, \n",
        "                                     norm=self.feature_extractor.normalize,\n",
        "                                     jitter=False)   \n",
        "                                     \n",
        "        self.warmup_batches  = warmup_epochs * (train_times*len(train_generator) + valid_times*len(valid_generator))   \n",
        "\n",
        "        ############################################\n",
        "        # Compile the model\n",
        "        ############################################\n",
        "\n",
        "        optimizer = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "        self.model.compile(loss=self.custom_loss, optimizer=optimizer)\n",
        "\n",
        "        ############################################\n",
        "        # Make a few callbacks\n",
        "        ############################################\n",
        "\n",
        "        early_stop = EarlyStopping(monitor='val_loss', \n",
        "                           min_delta=0.001, \n",
        "                           patience=3, \n",
        "                           mode='min', \n",
        "                           verbose=1)\n",
        "        checkpoint = ModelCheckpoint(saved_weights_name, \n",
        "                                     monitor='val_loss', \n",
        "                                     verbose=1, \n",
        "                                     save_best_only=True, \n",
        "                                     mode='min', \n",
        "                                     period=1)\n",
        "        tensorboard = TensorBoard(log_dir=os.path.expanduser('~/logs/'), \n",
        "                                  histogram_freq=0, \n",
        "                                  #write_batch_performance=True,\n",
        "                                  write_graph=True, \n",
        "                                  write_images=False)\n",
        "\n",
        "        ############################################\n",
        "        # Start the training process\n",
        "        ############################################        \n",
        "\n",
        "        self.model.fit_generator(generator        = train_generator, \n",
        "                                 steps_per_epoch  = len(train_generator) * train_times, \n",
        "                                 epochs           = warmup_epochs + nb_epochs, \n",
        "                                 verbose          = 2 if debug else 1,\n",
        "                                 validation_data  = valid_generator,\n",
        "                                 validation_steps = len(valid_generator) * valid_times,\n",
        "                                 callbacks        = [early_stop, checkpoint, tensorboard], \n",
        "                                 workers          = 3,\n",
        "                                 max_queue_size   = 8)\n",
        "\n",
        "        ############################################\n",
        "        # Compute mAP on the validation set\n",
        "        ############################################\n",
        "        average_precisions = self.evaluate(valid_generator)     \n",
        "\n",
        "        # print evaluation\n",
        "        for label, average_precision in average_precisions.items():\n",
        "            print(self.labels[label], '{:.4f}'.format(average_precision))\n",
        "        print('mAP: {:.4f}'.format(sum(average_precisions.values()) / len(average_precisions)))         \n",
        "\n",
        "    def evaluate(self, \n",
        "                 generator, \n",
        "                 iou_threshold=0.3,\n",
        "                 score_threshold=0.3,\n",
        "                 max_detections=100,\n",
        "                 save_path=None):\n",
        "        \"\"\" \n",
        "\n",
        "        # Arguments\n",
        "            generator       : The generator that represents the dataset to evaluate.\n",
        "            model           : The model to evaluate.\n",
        "            iou_threshold   : The threshold used to consider when a detection is positive or negative.\n",
        "            score_threshold : The score confidence threshold to use for detections.\n",
        "            max_detections  : The maximum number of detections to use per image.\n",
        "            save_path       : The path to save images with visualized detections to.\n",
        "        # Returns\n",
        "            A dict mapping class names to mAP scores.\n",
        "        \"\"\"    \n",
        "        # gather all detections and annotations\n",
        "        all_detections     = [[None for i in range(generator.num_classes())] for j in range(generator.size())]\n",
        "        all_annotations    = [[None for i in range(generator.num_classes())] for j in range(generator.size())]\n",
        "\n",
        "        for i in range(generator.size()):\n",
        "            raw_image = generator.load_image(i)\n",
        "            raw_height, raw_width, raw_channels = raw_image.shape\n",
        "\n",
        "            # make the boxes and the labels\n",
        "            pred_boxes  = self.predict(raw_image)\n",
        "\n",
        "            \n",
        "            score = np.array([box.score for box in pred_boxes])\n",
        "            pred_labels = np.array([box.label for box in pred_boxes])        \n",
        "            \n",
        "            if len(pred_boxes) > 0:\n",
        "                pred_boxes = np.array([[box.xmin*raw_width, box.ymin*raw_height, box.xmax*raw_width, box.ymax*raw_height, box.score] for box in pred_boxes])\n",
        "            else:\n",
        "                pred_boxes = np.array([[]])  \n",
        "            \n",
        "            # sort the boxes and the labels according to scores\n",
        "            score_sort = np.argsort(-score)\n",
        "            pred_labels = pred_labels[score_sort]\n",
        "            pred_boxes  = pred_boxes[score_sort]\n",
        "            \n",
        "            # copy detections to all_detections\n",
        "            for label in range(generator.num_classes()):\n",
        "                all_detections[i][label] = pred_boxes[pred_labels == label, :]\n",
        "                \n",
        "            annotations = generator.load_annotation(i)\n",
        "            \n",
        "            # copy detections to all_annotations\n",
        "            for label in range(generator.num_classes()):\n",
        "                all_annotations[i][label] = annotations[annotations[:, 4] == label, :4].copy()\n",
        "                \n",
        "        # compute mAP by comparing all detections and all annotations\n",
        "        average_precisions = {}\n",
        "        \n",
        "        for label in range(generator.num_classes()):\n",
        "            false_positives = np.zeros((0,))\n",
        "            true_positives  = np.zeros((0,))\n",
        "            scores          = np.zeros((0,))\n",
        "            num_annotations = 0.0\n",
        "\n",
        "            for i in range(generator.size()):\n",
        "                detections           = all_detections[i][label]\n",
        "                annotations          = all_annotations[i][label]\n",
        "                num_annotations     += annotations.shape[0]\n",
        "                detected_annotations = []\n",
        "\n",
        "                for d in detections:\n",
        "                    scores = np.append(scores, d[4])\n",
        "\n",
        "                    if annotations.shape[0] == 0:\n",
        "                        false_positives = np.append(false_positives, 1)\n",
        "                        true_positives  = np.append(true_positives, 0)\n",
        "                        continue\n",
        "\n",
        "                    overlaps            = compute_overlap(np.expand_dims(d, axis=0), annotations)\n",
        "                    assigned_annotation = np.argmax(overlaps, axis=1)\n",
        "                    max_overlap         = overlaps[0, assigned_annotation]\n",
        "\n",
        "                    if max_overlap >= iou_threshold and assigned_annotation not in detected_annotations:\n",
        "                        false_positives = np.append(false_positives, 0)\n",
        "                        true_positives  = np.append(true_positives, 1)\n",
        "                        detected_annotations.append(assigned_annotation)\n",
        "                    else:\n",
        "                        false_positives = np.append(false_positives, 1)\n",
        "                        true_positives  = np.append(true_positives, 0)\n",
        "\n",
        "            # no annotations -> AP for this class is 0 (is this correct?)\n",
        "            if num_annotations == 0:\n",
        "                average_precisions[label] = 0\n",
        "                continue\n",
        "\n",
        "            # sort by score\n",
        "            indices         = np.argsort(-scores)\n",
        "            false_positives = false_positives[indices]\n",
        "            true_positives  = true_positives[indices]\n",
        "\n",
        "            # compute false positives and true positives\n",
        "            false_positives = np.cumsum(false_positives)\n",
        "            true_positives  = np.cumsum(true_positives)\n",
        "\n",
        "            # compute recall and precision\n",
        "            recall    = true_positives / num_annotations\n",
        "            precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
        "\n",
        "            # compute average precision\n",
        "            average_precision  = compute_ap(recall, precision)  \n",
        "            average_precisions[label] = average_precision\n",
        "\n",
        "        return average_precisions    \n",
        "\n",
        "    def predict(self, image):\n",
        "        image_h, image_w, _ = image.shape\n",
        "        image = cv2.resize(image, (self.input_size, self.input_size))\n",
        "        image = self.feature_extractor.normalize(image)\n",
        "\n",
        "        input_image = image[:,:,::-1]\n",
        "        input_image = np.expand_dims(input_image, 0)\n",
        "        dummy_array = np.zeros((1,1,1,1,self.max_box_per_image,4))\n",
        "\n",
        "        netout = self.model.predict([input_image, dummy_array])[0]\n",
        "        boxes  = decode_netout(netout, self.anchors, self.nb_class)\n",
        "\n",
        "        return boxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IsxMtXBxMgv",
        "outputId": "ac485fdd-cb85-40dd-d6ac-4c4ac863bfda"
      },
      "source": [
        "import random\n",
        "\n",
        "num_anchors = 5\n",
        "\n",
        "def IOU(ann, centroids):\n",
        "    w, h = ann\n",
        "    similarities = []\n",
        "\n",
        "    for centroid in centroids:\n",
        "        c_w, c_h = centroid\n",
        "\n",
        "        if c_w >= w and c_h >= h:\n",
        "            similarity = w*h/(c_w*c_h)\n",
        "        elif c_w >= w and c_h <= h:\n",
        "            similarity = w*c_h/(w*h + (c_w-w)*c_h)\n",
        "        elif c_w <= w and c_h >= h:\n",
        "            similarity = c_w*h/(w*h + c_w*(c_h-h))\n",
        "        else: #means both w,h are bigger than c_w and c_h respectively\n",
        "            similarity = (c_w*c_h)/(w*h)\n",
        "        similarities.append(similarity) # will become (k,) shape\n",
        "\n",
        "    return np.array(similarities)\n",
        "\n",
        "def avg_IOU(anns, centroids):\n",
        "    n,d = anns.shape\n",
        "    sum = 0.\n",
        "\n",
        "    for i in range(anns.shape[0]):\n",
        "        sum+= max(IOU(anns[i], centroids))\n",
        "\n",
        "    return sum/n\n",
        "\n",
        "def print_anchors(centroids):\n",
        "    anchors = centroids.copy()\n",
        "\n",
        "    widths = anchors[:, 0]\n",
        "    sorted_indices = np.argsort(widths)\n",
        "\n",
        "    r = \"anchors: [\"\n",
        "    for i in sorted_indices[:-1]:\n",
        "        r += '%0.2f,%0.2f, ' % (anchors[i,0], anchors[i,1])\n",
        "\n",
        "    #there should not be comma after last anchor, that's why\n",
        "    r += '%0.2f,%0.2f' % (anchors[sorted_indices[-1:],0], anchors[sorted_indices[-1:],1])\n",
        "    r += \"]\"\n",
        "\n",
        "    print(r)\n",
        "\n",
        "def run_kmeans(ann_dims, anchor_num):\n",
        "    ann_num = ann_dims.shape[0]\n",
        "    iterations = 0\n",
        "    prev_assignments = np.ones(ann_num)*(-1)\n",
        "    iteration = 0\n",
        "    old_distances = np.zeros((ann_num, anchor_num))\n",
        "\n",
        "    indices = [random.randrange(ann_dims.shape[0]) for i in range(anchor_num)]\n",
        "    centroids = ann_dims[indices]\n",
        "    anchor_dim = ann_dims.shape[1]\n",
        "\n",
        "    while True:\n",
        "        distances = []\n",
        "        iteration += 1\n",
        "        for i in range(ann_num):\n",
        "            d = 1 - IOU(ann_dims[i], centroids)\n",
        "            distances.append(d)\n",
        "        distances = np.array(distances) # distances.shape = (ann_num, anchor_num)\n",
        "\n",
        "        print(\"iteration {}: dists = {}\".format(iteration, np.sum(np.abs(old_distances-distances))))\n",
        "\n",
        "        #assign samples to centroids\n",
        "        assignments = np.argmin(distances,axis=1)\n",
        "\n",
        "        if (assignments == prev_assignments).all() :\n",
        "            return centroids\n",
        "\n",
        "        #calculate new centroids\n",
        "        centroid_sums=np.zeros((anchor_num, anchor_dim), np.float)\n",
        "        for i in range(ann_num):\n",
        "            centroid_sums[assignments[i]]+=ann_dims[i]\n",
        "        for j in range(anchor_num):\n",
        "            centroids[j] = centroid_sums[j]/(np.sum(assignments==j) + 1e-6)\n",
        "\n",
        "        prev_assignments = assignments.copy()\n",
        "        old_distances = distances.copy()\n",
        "\n",
        "grid_w = tamanio/32\n",
        "grid_h = tamanio/32\n",
        "\n",
        "# run k_mean to find the anchors\n",
        "annotation_dims = []\n",
        "for image in train_imgs:\n",
        "    cell_w = image['width']/grid_w\n",
        "    cell_h = image['height']/grid_h\n",
        "\n",
        "    for obj in image['object']:\n",
        "        relative_w = (float(obj['xmax']) - float(obj['xmin']))/cell_w\n",
        "        relatice_h = (float(obj[\"ymax\"]) - float(obj['ymin']))/cell_h\n",
        "        annotation_dims.append(tuple(map(float, (relative_w,relatice_h))))\n",
        "\n",
        "\n",
        "annotation_dims = np.array(annotation_dims)\n",
        "centroids = run_kmeans(annotation_dims, num_anchors)\n",
        "\n",
        "# write anchors to file\n",
        "print('\\naverage IOU for', num_anchors, 'anchors:', '%0.2f' % avg_IOU(annotation_dims, centroids))\n",
        "print_anchors(centroids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration 1: dists = 2290.112045243449\n",
            "iteration 2: dists = 245.2851813235944\n",
            "iteration 3: dists = 150.55795012174022\n",
            "iteration 4: dists = 101.60362815636327\n",
            "iteration 5: dists = 98.3311137133062\n",
            "iteration 6: dists = 84.36466555226124\n",
            "iteration 7: dists = 77.34982783677569\n",
            "iteration 8: dists = 61.5008094510287\n",
            "iteration 9: dists = 61.79391735777294\n",
            "iteration 10: dists = 57.638654174177105\n",
            "iteration 11: dists = 42.73072428886134\n",
            "iteration 12: dists = 34.321024108548656\n",
            "iteration 13: dists = 26.789311086401632\n",
            "iteration 14: dists = 29.83913191415848\n",
            "iteration 15: dists = 26.396389638457862\n",
            "iteration 16: dists = 29.177890122676867\n",
            "iteration 17: dists = 17.22346889191372\n",
            "iteration 18: dists = 13.681242291689525\n",
            "iteration 19: dists = 12.357513575256721\n",
            "iteration 20: dists = 13.217870672624958\n",
            "iteration 21: dists = 21.977177031901476\n",
            "iteration 22: dists = 19.021873846985095\n",
            "iteration 23: dists = 16.59839116887542\n",
            "iteration 24: dists = 9.761624321731881\n",
            "iteration 25: dists = 14.504901717291371\n",
            "iteration 26: dists = 10.998451947378793\n",
            "iteration 27: dists = 13.15880462244413\n",
            "iteration 28: dists = 13.036842519790728\n",
            "iteration 29: dists = 17.2150986168633\n",
            "iteration 30: dists = 16.34040713483536\n",
            "iteration 31: dists = 9.76076596008678\n",
            "iteration 32: dists = 11.219292988717417\n",
            "iteration 33: dists = 12.250412228875987\n",
            "iteration 34: dists = 13.980401485931331\n",
            "iteration 35: dists = 10.201062823967064\n",
            "iteration 36: dists = 13.851904404466572\n",
            "iteration 37: dists = 15.59947966443141\n",
            "iteration 38: dists = 9.842615777979209\n",
            "iteration 39: dists = 1.5570349267696195\n",
            "iteration 40: dists = 1.404130386960063\n",
            "\n",
            "average IOU for 5 anchors: 0.68\n",
            "anchors: [2.65,1.86, 5.23,2.90, 5.91,5.82, 10.07,9.24, 10.51,5.00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Adx59Slo0Qmd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg9dWgA9xPCL",
        "outputId": "a1242b36-5a9b-4e02-9101-2649e8cde628"
      },
      "source": [
        "\n",
        "anchors = []\n",
        "for x in centroids:\n",
        "    anchors.append(x[0])\n",
        "    anchors.append(x[1])\n",
        "anchors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.227183268225541,\n",
              " 2.8986249545262943,\n",
              " 5.911987561525954,\n",
              " 5.822461086082797,\n",
              " 2.649796879599947,\n",
              " 1.8557984630261288,\n",
              " 10.070147686945068,\n",
              " 9.235920363617948,\n",
              " 10.513864385270942,\n",
              " 4.996553607527459]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0rRKC6jxSNf",
        "outputId": "85e01e10-7bd1-4302-b54c-495259b8b0b1"
      },
      "source": [
        "# instanciamos al modelo\n",
        "yolo = YOLO(input_size          = tamanio, \n",
        "            labels              = labels, \n",
        "            max_box_per_image   = 5,\n",
        "            anchors             = anchors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "(13, 13)\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 416, 416, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_1 (Model)                 (None, 13, 13, 1024) 50547936    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "DetectionLayer (Conv2D)         (None, 13, 13, 30)   30750       model_1[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 13, 13, 5, 6) 0           DetectionLayer[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 1, 1, 1, 5, 4 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 13, 13, 5, 6) 0           reshape_1[0][0]                  \n",
            "                                                                 input_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 50,578,686\n",
            "Trainable params: 50,558,014\n",
            "Non-trainable params: 20,672\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKwGiQoXYr0E",
        "outputId": "41d4e7e7-8ac0-4797-8bc7-ee5a804d4168"
      },
      "source": [
        "yolo.train(train_imgs         = train_imgs,\n",
        "           valid_imgs         = valid_imgs,\n",
        "           train_times        = 6,\n",
        "           valid_times        = 1,\n",
        "           nb_epochs          = 6, \n",
        "           learning_rate      = 1e-4, \n",
        "           batch_size         = 8,\n",
        "           warmup_epochs      = 2,\n",
        "           object_scale       = 5,\n",
        "           no_object_scale    = 1,\n",
        "           coord_scale        = 1,\n",
        "           class_scale        = 1,\n",
        "           saved_weights_name = mejores_pesos,\n",
        "           debug              = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-13-8cfdab92be6b>:59: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From <ipython-input-13-8cfdab92be6b>:202: Print (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2018-08-20.\n",
            "Instructions for updating:\n",
            "Use tf.print instead of tf.Print. Note that tf.print returns a no-output operator that directly prints the output. Outside of defuns or eager mode, this operator will not be executed unless it is directly specified in session.run or used as a control dependency for other operators. This is only a concern in graph mode. Below is an example of how to ensure tf.print executes in graph mode:\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/8\n",
            " - 262s - loss: 10.0505 - val_loss: 10.0091\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 10.00909, saving model to red_bache.h5\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "Epoch 2/8\n",
            " - 175s - loss: 10.0073 - val_loss: 10.0065\n",
            "\n",
            "Epoch 00002: val_loss improved from 10.00909 to 10.00648, saving model to red_bache.h5\n",
            "Epoch 3/8\n",
            " - 175s - loss: 1.2543 - val_loss: 0.5424\n",
            "\n",
            "Epoch 00003: val_loss improved from 10.00648 to 0.54240, saving model to red_bache.h5\n",
            "Epoch 4/8\n",
            " - 175s - loss: 0.7234 - val_loss: 1.8185\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.54240\n",
            "Epoch 5/8\n",
            " - 176s - loss: 0.4942 - val_loss: 0.5456\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.54240\n",
            "Epoch 6/8\n",
            " - 175s - loss: 0.4097 - val_loss: 0.9881\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.54240\n",
            "Epoch 00006: early stopping\n",
            "bache 0.0597\n",
            "mAP: 0.0597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAOhWXf3S76y"
      },
      "source": [
        "\n",
        "def draw_boxes(image, boxes, labels):\n",
        "    image_h, image_w, _ = image.shape\n",
        "\n",
        "    for box in boxes:\n",
        "        xmin = int(box.xmin*image_w)\n",
        "        ymin = int(box.ymin*image_h)\n",
        "        xmax = int(box.xmax*image_w)\n",
        "        ymax = int(box.ymax*image_h)\n",
        "\n",
        "        cv2.rectangle(image, (xmin,ymin), (xmax,ymax), (0,255,0), 3)\n",
        "        cv2.putText(image, \n",
        "                    labels[box.get_label()] + ' ' + str(box.get_score()), \n",
        "                    (xmin, ymin - 13), \n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
        "                    1e-3 * image_h, \n",
        "                    (0,255,0), 2)\n",
        "        \n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "pNVxa1oaTYFy",
        "outputId": "f552c281-cea6-48e3-e776-db1221848a8e"
      },
      "source": [
        "mejores_pesos = \"red_bache.h5\"\n",
        "\n",
        "image_path = \"/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/test/test3.jpg\"\n",
        "\n",
        "mi_yolo = YOLO(input_size          = tamanio, \n",
        "            labels              = labels, \n",
        "            max_box_per_image   = 1,\n",
        "            anchors             = anchors)\n",
        "\n",
        "mi_yolo.load_weights(mejores_pesos)\n",
        "\n",
        "image = cv2.imread(image_path)\n",
        "boxes = mi_yolo.predict(image)\n",
        "image = draw_boxes(image, boxes, labels)\n",
        "\n",
        "print('Detectados', len(boxes))\n",
        "\n",
        "cv2.imwrite(\"/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/test/test3.jpg\",image)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-60588e793c91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/UNIVERSIDAD_CENTRAL/2021-1S/INTELIGENCIA_ARTIFICIAL/test/test3.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m mi_yolo = YOLO(input_size          = tamanio, \n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mlabels\u001b[0m              \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mmax_box_per_image\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'YOLO' is not defined"
          ]
        }
      ]
    }
  ]
}